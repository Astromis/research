{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "35ef8462",
   "metadata": {},
   "source": [
    "This notebook is a whole testing pipeline. At first, it trains all models and then test them keeping the results in `report` dictionary. The headline shows which tokenizer is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8619aede-769f-4584-9115-0f2e0cf0c293",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoTokenizer, BertForNextSentencePrediction, Trainer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21d7534-58a4-4ebc-8260-4a7229e598ef",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5216a862-92a9-4504-9655-8d360167f237",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"final_complete/train_data.csv\", )\n",
    "df_eval = pd.read_csv(\"final_complete/eval_data.csv\", )\n",
    "df_test = pd.read_csv(\"final_complete/test_data.csv\",sep=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9032953",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer = AutoTokenizer.from_pretrained(\"models/ru_conversational_cased_L-12_H-768_A-12_pt_v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eec1e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = {\n",
    "    \"model_name\": [],\n",
    "    \"step\":[],\n",
    "    \"precision\": [],\n",
    "    \"recall\": [],\n",
    "    \"f1\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41f69ed-996f-45b6-98b7-3c548cdf252b",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7415cbf",
   "metadata": {},
   "source": [
    "## with bert tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf2f38e0-638f-47c1-9302-f362e1dc69c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_tokenized = df_train.copy()\n",
    "df_test_tokenized = df_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "33c7b3ed-ea32-4e7e-a163-b0fb26da739b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_tokenized.premise = df_train_tokenized.premise.apply(lambda x: ' '.join(bert_tokenizer.tokenize(x)))\n",
    "df_train_tokenized.hypothesis = df_train_tokenized.hypothesis.apply(lambda x: ' '.join(bert_tokenizer.tokenize(x)))\n",
    "\n",
    "df_test_tokenized.premise = df_test_tokenized.premise.apply(lambda x: ' '.join(bert_tokenizer.tokenize(x)))\n",
    "df_test_tokenized.hypothesis = df_test_tokenized.hypothesis.apply(lambda x: ' '.join(bert_tokenizer.tokenize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c13cd905-68ad-416b-9896-72898a909a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = list(zip(df_train_tokenized.premise.to_list(), df_train_tokenized.hypothesis.to_list()))\n",
    "train_texts = [' '.join(x) for x in train_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3d3d1e19-4507-42ad-a72b-0cd7cede8ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_texts = list(zip(df_test_tokenized.premise.to_list(), df_test_tokenized.hypothesis.to_list()))\n",
    "test_texts = [' '.join(x) for x in test_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bb7d7213-c21a-4c8b-84a0-28fc887b9ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs = CountVectorizer(max_features=100000, \n",
    "                       min_df= 5,\n",
    "                       max_df=0.9\n",
    "                      ).fit(train_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a5787dec-94c5-48df-98e5-35a5a6512979",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr = vecs.transform(train_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "786e5385-15a1-495e-a87f-16e9ea6ecab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<797701x59747 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 13447809 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e9961e8c-2607-4ac6-8b5c-444d97150f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(C=1, max_iter=1000 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "460b5c7d-e97e-4b74-9cbf-3a5e8237be1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, max_iter=1000)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(x_tr, df_train_tokenized.label, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "68dccb14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "56ba046b",
   "metadata": {},
   "outputs": [],
   "source": [
    "report[\"model_name\"].append(\"linear_regression-bert_tokenizer\")\n",
    "report[\"step\"].append(\"1000\")\n",
    "report[\"precision\"].append(precision_score(df_test_tokenized.label, clf.predict(vecs.transform(test_texts), )))\n",
    "report[\"recall\"].append(recall_score(df_test_tokenized.label, clf.predict(vecs.transform(test_texts), )))\n",
    "report[\"f1\"].append(f1_score(df_test_tokenized.label, clf.predict(vecs.transform(test_texts), )))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a991eb20",
   "metadata": {},
   "source": [
    "## with dict_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e6cfee3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = list(zip(df_train.premise.to_list(), df_train.hypothesis.to_list()))\n",
    "train_texts = [' '.join(x) for x in train_texts]\n",
    "\n",
    "test_texts = list(zip(df_test.premise.to_list(), df_test.hypothesis.to_list()))\n",
    "test_texts = [' '.join(x) for x in test_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a3745e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs = CountVectorizer(max_features=100000, \n",
    "                       min_df= 5,\n",
    "                       max_df=0.9\n",
    "                      ).fit(train_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bb14a87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr = vecs.transform(train_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "763f26d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<797701x100000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 11521611 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ea36007b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(C=1, max_iter=1000 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e6410171",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, max_iter=1000)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(x_tr, df_train.label, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4a205a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "report[\"model_name\"].append(\"linear_regression-dict_tokenizer\")\n",
    "report[\"step\"].append(\"1000\")\n",
    "report[\"precision\"].append(precision_score(df_test_tokenized.label, clf.predict(vecs.transform(test_texts), )))\n",
    "report[\"recall\"].append(recall_score(df_test_tokenized.label, clf.predict(vecs.transform(test_texts), )))\n",
    "report[\"f1\"].append(f1_score(df_test_tokenized.label, clf.predict(vecs.transform(test_texts), )))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b20ce4-aba5-42da-8bf3-95d67cf9d019",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb636a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = list(zip(df_train.premise, df_train.hypothesis, df_train.label))\n",
    "test_data = list(zip(df_test.premise, df_test.hypothesis, df_test.label))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59c3c95",
   "metadata": {},
   "source": [
    "## Conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3b93968",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = {\n",
    "    \"alighment_len\":100,\n",
    "    \"lr\": 1e-3,\n",
    "    \"device\":\"cuda\",\n",
    "    \"epochs\":3,\n",
    "    \"batch_sze\":32,\n",
    "}\n",
    "\n",
    "model_config = {\n",
    "    \"num_classes\": 2,\n",
    "    \"embed_dim\":256,\n",
    "    \"hidden_dim\":64,\n",
    "    \"n_layers\":2,\n",
    "    \"is_bidirectional\":True,\n",
    "    \"rnn_type\": \"LSTM\",\n",
    "    \"intermidiate_dim\":128\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95aea89b",
   "metadata": {},
   "source": [
    "## With bert tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f5a98e",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f68f5c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total param size: 26067202\n"
     ]
    }
   ],
   "source": [
    "model = get_rnn_model(vocab_size=bert_tokenizer.vocab_size, \n",
    "                      num_classes=model_config[\"num_classes\"], \n",
    "                      embed_dim=model_config[\"embed_dim\"], \n",
    "                      hidden_dim=model_config[\"hidden_dim\"], \n",
    "                      n_layers=model_config[\"n_layers\"], \n",
    "                      is_bidirectional=model_config[\"is_bidirectional\"], \n",
    "                      rnn_type=model_config[\"rnn_type\"], \n",
    "                      padding_idx=bert_tokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c59307e9-649b-45ce-bf38-5afb717ca0c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01181793212890625,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 24929,
       "unit": "batch",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4de46da132842a5bf318a12c3317ec2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24929 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.015686750411987305,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 24929,
       "unit": "batch",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "701ea8d262aa472680a6c1c01d343023",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24929 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.015611886978149414,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 24929,
       "unit": "batch",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd94b0e8c042424085d7895cff9ede93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24929 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_model(data=train_data, model=model, tokenizer=bert_tokenizer, \n",
    "            alighment_len=train_config[\"alighment_len\"],\n",
    "            device=train_config[\"device\"], \n",
    "            epochs=train_config[\"epochs\"], \n",
    "            learning_rate=train_config[\"lr\"], \n",
    "            batch_size=train_config[\"batch_sze\"], \n",
    "            is_siames=False, \n",
    "            save_path=\"trained_models/rnn-bert_tokenizer\", divider=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4fcc9341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): Embedding(100792, 256, padding_idx=0, max_norm=1)\n",
       "  (encoder): Encoder(\n",
       "    (rnn): LSTM(256, 64, num_layers=4, dropout=0.1, bidirectional=True)\n",
       "  )\n",
       "  (attention): Attention()\n",
       "  (decoder): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.load_state_dict(torch.load(\"trained_models/rnn-bert_tokenizer/model_66477.cpkt\"))\n",
    "#model = model.to(\"cuda\")\n",
    "#model.eval()\n",
    "#preds, corrs = inference_model(data=test_data, model=model, tokenizer=bert_tokenizer, alighment_len=100,\n",
    "#          device=\"cuda\", batch_size=16, is_siames=False)\n",
    "#sum(preds == corrs) / len(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a091d6a5",
   "metadata": {},
   "source": [
    "### Siames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c148121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total param size: 26083970\n"
     ]
    }
   ],
   "source": [
    "model = get_siames_model(vocab_size=bert_tokenizer.vocab_size, \n",
    "                          num_classes=model_config[\"num_classes\"], \n",
    "                          embed_dim=model_config[\"embed_dim\"], \n",
    "                          hidden_dim=model_config[\"hidden_dim\"],\n",
    "                         intermidiate_dim=model_config[\"intermidiate_dim\"],\n",
    "                          n_layers=model_config[\"n_layers\"], \n",
    "                          is_bidirectional=model_config[\"is_bidirectional\"], \n",
    "                          rnn_type=model_config[\"rnn_type\"], \n",
    "                          padding_idx=bert_tokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90a7dcff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.012053251266479492,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 24929,
       "unit": "batch",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b73d85720e1f437fb7160068f56aeaac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24929 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02092123031616211,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 24929,
       "unit": "batch",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc399ecd18e14c188593bb964f0cab3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24929 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.015388011932373047,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 24929,
       "unit": "batch",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6446a499f84548b59a84e5fd54a0faec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24929 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_model(data=train_data, \n",
    "            model=model, \n",
    "            tokenizer=bert_tokenizer, \n",
    "            alighment_len=train_config[\"alighment_len\"],\n",
    "            device=train_config[\"device\"], \n",
    "            epochs=train_config[\"epochs\"], \n",
    "            learning_rate=train_config[\"lr\"], \n",
    "            batch_size=train_config[\"batch_sze\"], \n",
    "            is_siames=True, \n",
    "            save_path=\"trained_models/siames_rnn_rnn-bert_tokenizer\", divider=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b0820c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SiamesRNN(\n",
       "  (embedding): Embedding(100792, 256, padding_idx=0, max_norm=1, scale_grad_by_freq=True)\n",
       "  (encoder): Encoder(\n",
       "    (rnn): LSTM(256, 64, num_layers=4, dropout=0.1, bidirectional=True)\n",
       "  )\n",
       "  (attention): Attention()\n",
       "  (decoder): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (classifier_head): Linear(in_features=256, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.load_state_dict(torch.load(\"trained_models/siames_rnn-bert_tokenizer/model_66477.cpkt\"))\n",
    "#model = model.to(\"cuda\")\n",
    "#model.eval()\n",
    "#preds, corrs = inference_model(data=test_data, model=model, tokenizer=bert_tokenizer, alighment_len=100,\n",
    "#          device=\"cuda\", batch_size=16, is_siames=True)\n",
    "#print(sum((preds == corrs)) / len(preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e061c69",
   "metadata": {},
   "source": [
    "# With usual tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8cd0dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_tokenozer = DictTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "42326aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_tokenozer.train(df_train.premise.to_list() + df_train.hypothesis.to_list())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54994337",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dea05eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total param size: 91892226\n"
     ]
    }
   ],
   "source": [
    "model = get_rnn_model(vocab_size=dict_tokenozer.vocab_size, \n",
    "                      num_classes=model_config[\"num_classes\"], \n",
    "                      embed_dim=model_config[\"embed_dim\"], \n",
    "                      hidden_dim=model_config[\"hidden_dim\"], \n",
    "                      n_layers=model_config[\"n_layers\"], \n",
    "                      is_bidirectional=model_config[\"is_bidirectional\"], \n",
    "                      rnn_type=model_config[\"rnn_type\"], \n",
    "                      padding_idx=dict_tokenozer.padding_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "24be664d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01368093490600586,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 24929,
       "unit": "batch",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6b65ccf1fd24f3e8a398ee6166973a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24929 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011310577392578125,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 24929,
       "unit": "batch",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "732f18ceced944e2b9851682fa05cc01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24929 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.015598535537719727,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 24929,
       "unit": "batch",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d2edd7105814fb7a5a3148e4f5a3363",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24929 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_model(data=train_data, model=model, tokenizer=dict_tokenozer, \n",
    "            alighment_len=train_config[\"alighment_len\"],\n",
    "            device=train_config[\"device\"], \n",
    "            epochs=train_config[\"epochs\"], \n",
    "            learning_rate=train_config[\"lr\"], \n",
    "            batch_size=train_config[\"batch_sze\"], \n",
    "            is_siames=False, \n",
    "            save_path=\"trained_models/rnn-dict_tokenizer\", divider=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "99022c08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): Embedding(357921, 256, padding_idx=357919, max_norm=1)\n",
       "  (encoder): Encoder(\n",
       "    (rnn): LSTM(256, 64, num_layers=4, dropout=0.1, bidirectional=True)\n",
       "  )\n",
       "  (attention): Attention()\n",
       "  (decoder): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.load_state_dict(torch.load(\"trained_models/rnn-dict_tokenizer/model_83096.cpkt\"))\n",
    "#model = model.to(\"cuda\")\n",
    "#model.eval()\n",
    "#preds, corrs = inference_model(data=test_data, model=model, tokenizer=dict_tokenozer, alighment_len=50,\n",
    "#          device=\"cuda\", batch_size=16, is_siames=False)\n",
    "#print(sum(preds == corrs) / len(preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee7df96",
   "metadata": {},
   "source": [
    "### Siames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "92a188c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total param size: 91908994\n"
     ]
    }
   ],
   "source": [
    "model = get_siames_model(vocab_size=dict_tokenozer.vocab_size, \n",
    "                          num_classes=model_config[\"num_classes\"], \n",
    "                          embed_dim=model_config[\"embed_dim\"], \n",
    "                          hidden_dim=model_config[\"hidden_dim\"],\n",
    "                         intermidiate_dim=model_config[\"intermidiate_dim\"],\n",
    "                          n_layers=model_config[\"n_layers\"], \n",
    "                          is_bidirectional=model_config[\"is_bidirectional\"], \n",
    "                          rnn_type=model_config[\"rnn_type\"], \n",
    "                          padding_idx=dict_tokenozer.padding_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8de5ca59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011501550674438477,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 24929,
       "unit": "batch",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b077581dcc2412f87f419f15dc4fdf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24929 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011675357818603516,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 24929,
       "unit": "batch",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d955521a4ab412a977b62d4c113c3d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24929 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011539936065673828,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 24929,
       "unit": "batch",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cfd797d6cf94df0970e9f243b1cf28c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24929 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_model(data=train_data, \n",
    "            model=model, \n",
    "            tokenizer=bert_tokenizer, \n",
    "            alighment_len=train_config[\"alighment_len\"],\n",
    "            device=train_config[\"device\"], \n",
    "            epochs=train_config[\"epochs\"], \n",
    "            learning_rate=train_config[\"lr\"], \n",
    "            batch_size=train_config[\"batch_sze\"], \n",
    "            is_siames=True, \n",
    "            save_path=\"trained_models/siames_rnn-dict_tokenizer\", divider=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22a8073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SiamesRNN(\n",
       "  (embedding): Embedding(357921, 256, padding_idx=357919, max_norm=1, scale_grad_by_freq=True)\n",
       "  (encoder): Encoder(\n",
       "    (rnn): LSTM(256, 64, num_layers=4, dropout=0.1, bidirectional=True)\n",
       "  )\n",
       "  (attention): Attention()\n",
       "  (decoder): Linear(in_features=128, out_features=256, bias=True)\n",
       "  (classifier_head): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.load_state_dict(torch.load(\"trained_models/siames_rnn-dict_tokenizer/model_49858.cpkt\"))\n",
    "#model = model.to(\"cuda\")\n",
    "#model.eval()\n",
    "#preds, corrs = inference_model(data=test_data, model=model, tokenizer=dict_tokenozer, alighment_len=100,\n",
    "#          device=\"cuda\", batch_size=16, is_siames=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "18851661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5373993095512083"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(preds == corrs) / len(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516374b5",
   "metadata": {},
   "source": [
    "# SentenceBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "75a0f198",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_st = SentenceTransformer(\"models/sbert_output_softmax/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eef1545b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceBERTClassifier(model_st, \n",
    "                               sentence_embedding_dimension=256,\n",
    "                               num_labels=2\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4f0f6e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PairedTextDataset(df_train.premise.to_list(), \n",
    "                                  df_train.hypothesis.to_list(), \n",
    "                                  df_train.label.to_list())\n",
    "\n",
    "dataloader = DataLoader(train_dataset, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "38308525",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.sent_bert_model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4bb8d507",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "lr = 10e-5\n",
    "divider = 3\n",
    "save_path = \"trained_models/sbert-sent_embeddings_256-3_epochs_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "28ac9b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0531005859375,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 99713,
       "unit": "batch",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06f12fdbeaaa4b47b8c7298563049f25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99713 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011279582977294922,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 99713,
       "unit": "batch",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe89d80068094a23904b2090f74bcfa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99713 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011787652969360352,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 99713,
       "unit": "batch",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51e6201d3589442b8aaea2efe72f7d51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99713 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr , )\n",
    "model.train()\n",
    "model = model.to(\"cuda\")\n",
    "loss_avg = []\n",
    "save_counter = 0\n",
    "already_saved = 0\n",
    "if save_path is not None:\n",
    "    if not isinstance(save_path, Path):\n",
    "        save_path = Path(save_path)\n",
    "    if not save_path.exists():\n",
    "        os.mkdir(save_path)\n",
    "    save_after = len(dataloader) // divider\n",
    "for e in range(epochs):\n",
    "    with tqdm(dataloader, unit=\"batch\") as tepoch:\n",
    "        for batch in tepoch:\n",
    "            tepoch.set_description(f\"Epoch {e}\")\n",
    "            batch[\"label\"] = batch[\"label\"].to(\"cuda\")\n",
    "            model.zero_grad()\n",
    "            score = model(batch[\"text_pair\"])\n",
    "            loss = loss_function(score, batch[\"label\"].squeeze())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_avg.append(loss.item())\n",
    "            tepoch.set_postfix(loss=np.mean(loss_avg), )\n",
    "            save_counter += 1\n",
    "            if save_counter > save_after:\n",
    "                torch.save(model.state_dict(), save_path / f\"model_{save_counter + save_after*already_saved}.cpkt\")\n",
    "                save_counter = 0\n",
    "                already_saved += 1\n",
    "torch.save(model.state_dict(), save_path / f\"model_final.cpkt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8ab99c",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3344ab7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "39acd9d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_8310.cpkt True\n",
      "model_16619.cpkt True\n",
      "model_24928.cpkt True\n",
      "model_33237.cpkt True\n",
      "model_41546.cpkt True\n",
      "model_49855.cpkt True\n",
      "model_58164.cpkt True\n",
      "model_66473.cpkt True\n",
      "model_final.cpkt True\n",
      "Total param size: 26067202\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011114120483398438,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 544,
       "unit": "batch",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cd4fbcd68024538a6d41d3559af71da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/544 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:rnn-bert_tokenizer, pre:0.5602196939976462, rec:0.7145359019264448, f1:0.6280373831775702\n",
      "model_8310.cpkt True\n",
      "model_16619.cpkt True\n",
      "model_24928.cpkt True\n",
      "model_33237.cpkt True\n",
      "model_41546.cpkt True\n",
      "model_49855.cpkt True\n",
      "model_58164.cpkt True\n",
      "model_66473.cpkt True\n",
      "model_final.cpkt True\n",
      "Total param size: 26083970\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.010914802551269531,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 544,
       "unit": "batch",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c23bd22e39834f049061386cf7dea483",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/544 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:siames_rnn_rnn-bert_tokenizer, pre:0.6598812553011026, rec:0.38929196897673257, f1:0.48969315499606614\n",
      "model_8310.cpkt True\n",
      "model_16619.cpkt True\n",
      "model_24928.cpkt True\n",
      "model_33237.cpkt True\n",
      "model_41546.cpkt True\n",
      "model_49855.cpkt True\n",
      "model_58164.cpkt True\n",
      "model_66473.cpkt True\n",
      "model_final.cpkt True\n",
      "Total param size: 91892226\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011022329330444336,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 544,
       "unit": "batch",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0a07650146a43eaad1f0252213db8ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/544 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:rnn-dict_tokenizer, pre:0.6025316455696202, rec:0.4763572679509632, f1:0.5320665083135392\n",
      "model_8310.cpkt True\n",
      "model_16619.cpkt True\n",
      "model_24928.cpkt True\n",
      "model_33237.cpkt True\n",
      "model_41546.cpkt True\n",
      "model_49855.cpkt True\n",
      "model_58164.cpkt True\n",
      "model_66473.cpkt True\n",
      "model_final.cpkt True\n",
      "Total param size: 91908994\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011380434036254883,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 544,
       "unit": "batch",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbffa570d190423ab867b5d00b0b0743",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/544 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:siames_rnn-dict_tokenizer, pre:0.408, rec:0.06379784838628971, f1:0.11034184335785374\n",
      "model_33238.cpkt True\n",
      "model_66475.cpkt True\n",
      "model_99712.cpkt True\n",
      "model_132949.cpkt True\n",
      "model_166186.cpkt True\n",
      "model_199423.cpkt True\n",
      "model_232660.cpkt True\n",
      "model_265897.cpkt True\n",
      "model_final.cpkt True\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.010953664779663086,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 272,
       "unit": "batch",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "498da454d5b2499c91d8a75e5f43d12d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/272 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file models/trained_models/results_fine_tuned_ru_conversational_bert/checkpoint-150000/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"ru_conversational_cased_L-12_H-768_A-12_pt_v1\",\n",
      "  \"architectures\": [\n",
      "    \"BertForNextSentencePrediction\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading weights file models/trained_models/results_fine_tuned_ru_conversational_bert/checkpoint-150000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:sbert-sent_embeddings_256-3_epochs, pre:0.7869053457577244, rec:0.8028521391043283, f1:0.794798761609907\n",
      "checkpoint-135000 True\n",
      "checkpoint-150000 True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing BertForNextSentencePrediction.\n",
      "\n",
      "All the weights of BertForNextSentencePrediction were initialized from the model checkpoint at models/trained_models/results_fine_tuned_ru_conversational_bert/checkpoint-150000.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForNextSentencePrediction for predictions without further training.\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 8690\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:results_fine_tuned_ru_conversational_bert, pre:0.8220277169948942, rec:0.8458844133099825, f1:0.8337854500616523\n"
     ]
    }
   ],
   "source": [
    "base = Path(\"models/trained_models/\")\n",
    "\n",
    "all_corrects = []\n",
    "all_predictions = {}\n",
    "for model_dir in os.listdir(base):\n",
    "    model_base = base/model_dir\n",
    "    for model_checkpoint in os.listdir(model_base):\n",
    "        if (\"final\" not in model_checkpoint) and (\"15000\" not in model_checkpoint):\n",
    "            continue\n",
    "        if model_checkpoint == \".ipynb_checkpoints\":\n",
    "            continue\n",
    "        if \"rnn\" in model_dir:\n",
    "            if \"dict_tokenizer\" in model_dir:\n",
    "                tokenizer = dict_tokenozer\n",
    "                padding_idx = dict_tokenozer.padding_idx\n",
    "            else:\n",
    "                tokenizer = bert_tokenizer\n",
    "                padding_idx = bert_tokenizer.pad_token_id\n",
    "            if \"siames\" in model_dir:\n",
    "                model = get_siames_model(vocab_size=tokenizer.vocab_size, \n",
    "                                          num_classes=model_config[\"num_classes\"], \n",
    "                                          embed_dim=model_config[\"embed_dim\"], \n",
    "                                          hidden_dim=model_config[\"hidden_dim\"],\n",
    "                                         intermidiate_dim=model_config[\"intermidiate_dim\"],\n",
    "                                          n_layers=model_config[\"n_layers\"], \n",
    "                                          is_bidirectional=model_config[\"is_bidirectional\"], \n",
    "                                          rnn_type=model_config[\"rnn_type\"], \n",
    "                                          padding_idx=padding_idx)\n",
    "                is_siames = True\n",
    "            else:\n",
    "                model = get_rnn_model(vocab_size=tokenizer.vocab_size, \n",
    "                                      num_classes=model_config[\"num_classes\"], \n",
    "                                      embed_dim=model_config[\"embed_dim\"], \n",
    "                                      hidden_dim=model_config[\"hidden_dim\"], \n",
    "                                      n_layers=model_config[\"n_layers\"], \n",
    "                                      is_bidirectional=model_config[\"is_bidirectional\"], \n",
    "                                      rnn_type=model_config[\"rnn_type\"], \n",
    "                                      padding_idx=padding_idx)\n",
    "                is_siames = False\n",
    "\n",
    "            model.load_state_dict(torch.load(model_base/model_checkpoint))\n",
    "            model = model.to(\"cuda\")\n",
    "            model.eval()\n",
    "\n",
    "            predictions, corrects = inference_model(data=test_data, model=model, tokenizer=tokenizer, alighment_len=50,\n",
    "                      device=\"cuda\", batch_size=16, is_siames=is_siames)\n",
    "        elif \"sbert\" in model_dir:\n",
    "            model = SentenceBERTClassifier(model_st, \n",
    "                                           sentence_embedding_dimension=256,\n",
    "                                           num_labels=2\n",
    "                                          )\n",
    "            model.load_state_dict(torch.load(model_base/model_checkpoint))\n",
    "            model = model.to(\"cuda\")\n",
    "            model.eval()\n",
    "            predictions = inference_sbert(df_test, model)\n",
    "            corrects = df_test.label.to_list()\n",
    "        else:\n",
    "            model = BertForNextSentencePrediction.from_pretrained(model_base/model_checkpoint)\n",
    "            tokenized_texts_ts = bert_tokenizer(df_test.premise.to_list(), \n",
    "                                                df_test.hypothesis.to_list(), return_tensors='pt',\n",
    "                                truncation=True, max_length=512, padding = 'max_length',)\n",
    "            test_dataset = TextsLabelsDataset(tokenized_texts_ts, df_test.label.to_list())\n",
    "            trainer = Trainer(model=model,)\n",
    "            test_predictions = trainer.predict(test_dataset)\n",
    "            predictions = np.argmax(test_predictions[0], axis=1)\n",
    "            corrects = df_test.label.to_list()\n",
    "        if \"fine_tuned\" in model_dir:\n",
    "            model_checkpoint = model_checkpoint.split(\"-\")[1]\n",
    "        else:\n",
    "            model_checkpoint = model_checkpoint.split(\"_\")[1].split(\".\")[0]\n",
    "        report[\"model_name\"].append(model_dir)\n",
    "        report[\"step\"].append(model_checkpoint)\n",
    "        report[\"precision\"].append(precision_score(corrects, predictions))\n",
    "        report[\"recall\"].append(recall_score(corrects, predictions))\n",
    "        report[\"f1\"].append(f1_score(corrects, predictions))\n",
    "        all_corrects.append((model_dir, predictions))\n",
    "        print(f\"model:{report['model_name'][-1]}, pre:{report['precision'][-1]}, rec:{report['recall'][-1]}, f1:{report['f1'][-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "74d1af68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "759cc16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m_name, preds in all_corrects:\n",
    "    df_test[m_name] = preds == df_test.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e9dfae90",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [x[0] for x in all_corrects]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c26192ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrr}\n",
      " & rnn-bert_tokenizer & siames_rnn_rnn-bert_tokenizer & rnn-dict_tokenizer & siames_rnn-dict_tokenizer & sbert-sent_embeddings_256-3_epochs & results_fine_tuned_ru_conversational_bert \\\\\n",
      "chat &  &  &  &  &  &  \\\\\n",
      "balichat_woman & 0.694686 & 0.687923 & 0.658937 & 0.579710 & 0.857005 & 0.883092 \\\\\n",
      "borussia_chat & 0.584541 & 0.627053 & 0.604831 & 0.568116 & 0.798068 & 0.821256 \\\\\n",
      "chat_suicidnikov & 0.538164 & 0.575845 & 0.578744 & 0.533333 & 0.783575 & 0.826087 \\\\\n",
      "cotedazurchat & 0.574879 & 0.628019 & 0.588406 & 0.536232 & 0.762319 & 0.793237 \\\\\n",
      "easypeasycodechat & 0.702213 & 0.519115 & 0.555332 & 0.277666 & 0.859155 & 0.885312 \\\\\n",
      "openwrt_ru & 0.555907 & 0.620253 & 0.566456 & 0.527426 & 0.787975 & 0.835443 \\\\\n",
      "orange_sosedi & 0.625121 & 0.647343 & 0.657971 & 0.533333 & 0.817391 & 0.849275 \\\\\n",
      "sling38 & 0.685990 & 0.655072 & 0.667633 & 0.512077 & 0.841546 & 0.889855 \\\\\n",
      "terrariaphone & 0.577778 & 0.624155 & 0.618357 & 0.543961 & 0.800966 & 0.840580 \\\\\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pd.options.display.float_format = '{:,.3f}'.format\n",
    "print(df_test.groupby(\"chat\")[model_names].agg(lambda x: sum(x) / len(x)).style.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "f5d82c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = df_test.groupby(\"chat\")[model_names].agg(lambda x: sum(x) / len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "74557023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrr}\n",
      " & rnn-bert_tokenizer & siames_rnn_rnn-bert_tokenizer & rnn-dict_tokenizer & siames_rnn-dict_tokenizer & sbert-sent_embeddings_256-3_epochs & results_fine_tuned_ru_conversational_bert \\\\\n",
      "chat &  &  &  &  &  &  \\\\\n",
      "balichat_woman & 0.695 & 0.688 & 0.659 & 0.580 & 0.857 & 0.883 \\\\\n",
      "borussia_chat & 0.585 & 0.627 & 0.605 & 0.568 & 0.798 & 0.821 \\\\\n",
      "chat_suicidnikov & 0.538 & 0.576 & 0.579 & 0.533 & 0.784 & 0.826 \\\\\n",
      "cotedazurchat & 0.575 & 0.628 & 0.588 & 0.536 & 0.762 & 0.793 \\\\\n",
      "easypeasycodechat & 0.702 & 0.519 & 0.555 & 0.278 & 0.859 & 0.885 \\\\\n",
      "openwrt_ru & 0.556 & 0.620 & 0.566 & 0.527 & 0.788 & 0.835 \\\\\n",
      "orange_sosedi & 0.625 & 0.647 & 0.658 & 0.533 & 0.817 & 0.849 \\\\\n",
      "sling38 & 0.686 & 0.655 & 0.668 & 0.512 & 0.842 & 0.890 \\\\\n",
      "terrariaphone & 0.578 & 0.624 & 0.618 & 0.544 & 0.801 & 0.841 \\\\\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df_result.style.format( precision=3).to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7557ce8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "893e8b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 f1    step\n",
      "model_name                                                 \n",
      "linear_regression-bert_tokenizer           0.501125    1000\n",
      "linear_regression-dict_tokenizer           0.500118    1000\n",
      "results_fine_tuned_ru_conversational_bert  0.833785  150000\n",
      "rnn-bert_tokenizer                         0.628037   final\n",
      "rnn-dict_tokenizer                         0.566009   final\n",
      "sbert-sent_embeddings_256-3_epochs         0.797450   final\n",
      "siames_rnn-dict_tokenizer                  0.505583   final\n",
      "siames_rnn_rnn-bert_tokenizer              0.539064   final\n"
     ]
    }
   ],
   "source": [
    "print(df.groupby([\"model_name\", ])[[ 'f1', \"step\"]].agg(\"max\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefeecc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
